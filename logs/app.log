18:05:15.737 [error] `inotify-tools` is needed to run `file_system` for your system, check https://github.com/rvoicilas/inotify-tools/wiki for more information about how to install it. If it's already installed but not be found, appoint executable file with `config.exs` or `FILESYSTEM_FSINOTIFY_EXECUTABLE_FILE` env.
18:05:15.737 [warn] Could not start Phoenix live-reload because we cannot listen to the file system.
You don't need to worry! This is an optional feature used during development to
refresh your browser when you save files and it does not affect production.

18:05:18.665 [info] Running WeatherApp2Web.Endpoint with cowboy 2.10.0 at 127.0.0.1:4000 (http)
18:05:18.675 [info] Access WeatherApp2Web.Endpoint at http://localhost:4000
18:06:00.310 [info] Iniciando crawler
18:19:11.128 [info] Iniciando crawler
18:19:52.933 [info] Iniciando crawler
18:20:09.261 [info] Iniciando crawler
18:24:18.294 [info] Iniciando crawler
18:36:26.041 [error] `inotify-tools` is needed to run `file_system` for your system, check https://github.com/rvoicilas/inotify-tools/wiki for more information about how to install it. If it's already installed but not be found, appoint executable file with `config.exs` or `FILESYSTEM_FSINOTIFY_EXECUTABLE_FILE` env.
18:36:26.044 [warn] Could not start Phoenix live-reload because we cannot listen to the file system.
You don't need to worry! This is an optional feature used during development to
refresh your browser when you save files and it does not affect production.

18:36:28.641 [info] Running WeatherApp2Web.Endpoint with cowboy 2.10.0 at 127.0.0.1:4000 (http)
18:36:28.661 [info] Access WeatherApp2Web.Endpoint at http://localhost:4000
18:36:39.829 [info] Iniciando crawler
18:38:09.656 [info] Iniciando crawler
18:42:17.170 [info] Iniciando crawler
18:44:57.983 [info] Iniciando crawler
18:45:01.553 [error] Erro ao obter dados (table_not_found): Tabela não encontrada
18:51:54.410 [info] Iniciando crawler
18:53:39.051 [info] Iniciando crawler
18:58:07.815 [info] Iniciando crawler
19:00:00.877 [info] Iniciando crawler
19:00:04.276 [error] ** (ArgumentError) cannot convert the given list to a string.

To be converted to a string, a list must either be empty or only
contain the following elements:

  * strings
  * integers representing Unicode code points
  * a list containing one of these three elements

Please check the given list or call inspect/1 to get the list representation, got:

[{"html", [{"lang", "en"}], [{"head", [], [{"meta", [{"charset", "utf-8"}], []}, {"title", [], ["Error"]}]}, {"body", [], [{"pre", [], ["Cannot GET /climatologia-agricola2"]}]}]}]

    (elixir 1.15.7) lib/list.ex:1084: List.to_string/1
    (weather_app_2 0.1.0) lib/weather_app_2/crawler/crawler.ex:60: WeatherApp2.Crawler.check_if_table_exists/1
    (weather_app_2 0.1.0) lib/weather_app_2/crawler/crawler.ex:37: WeatherApp2.Crawler.handle_table_info/1
    (elixir 1.15.7) src/elixir.erl:396: :elixir.eval_external_handler/3
    (quantum 3.5.0) lib/quantum/executor.ex:98: anonymous fn/4 in Quantum.Executor.run/5
    (telemetry 1.2.1) /home/thiago/projetos/weather_app_2/deps/telemetry/src/telemetry.erl:321: :telemetry.span/3
    (quantum 3.5.0) lib/quantum/executor.ex:97: anonymous fn/6 in Quantum.Executor.run/5
    (elixir 1.15.7) lib/task/supervised.ex:101: Task.Supervised.invoke_mfa/2

19:00:37.363 [info] Iniciando crawler
19:00:42.228 [error] Erro ao obter dados (table_not_found): Tabela não encontrada
 <!DOCTYPE html>
<html lang="en"><head>
<meta charset="utf-8">
<title>Error</title>
</head>
<body>
<pre>Cannot GET /climatologia-agricola2</pre>


</body></html>

19:02:20.349 [info] Iniciando crawler
19:02:26.332 [error] Erro ao obter dados (table_not_found): Tabela não encontrada
 <!DOCTYPE html> <html lang="en"><head> <meta charset="utf-8"> <title>Error</title> </head> <body> <pre>Cannot GET /climatologia-agricola2</pre>   </body></html> 
19:03:31.466 [info] Iniciando crawler
19:05:04.178 [info] Iniciando crawler
19:05:12.727 [info] Crawler finalizado
19:12:30.595 [info] Iniciando crawler
19:18:10.532 [info] Iniciando crawler
19:18:20.012 [info] Medição realizada em 25/11/2023 19:08:06
19:18:20.012 [info] Crawler finalizado
